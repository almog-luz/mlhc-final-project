{
 "cells": [
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\"cell_type\": \"markdown\", \"metadata\": {}, \"source\": [\"# MLHC: Lean Training Notebook\\n\",\"\\n\",\"Minimal end-to-end training: configure, (optionally) build labels, train models, inspect metrics.\"]},\n",
    "  {\"cell_type\": \"code\", \"execution_count\": null, \"metadata\": {}, \"outputs\": [], \"source\": [\n",
    "    \"# Path setup so 'project' package imports regardless of IDE CWD\\n\",\n",
    "    \"import sys, os, pathlib\\n\",\n",
    "    \"cands = [pathlib.Path.cwd(), pathlib.Path.cwd().parent, pathlib.Path.cwd()/ 'project', pathlib.Path.cwd().parent / 'project']\\n\",\n",
    "    \"for p in cands:\\n\",\n",
    "    \"    if p.is_dir() and str(p) not in sys.path:\\n\",\n",
    "    \"        sys.path.insert(0, str(p))\\n\",\n",
    "    \"print('sys.path[0]=', sys.path[0])\\n\"\n",
    "  ]},\n",
    "  {\"cell_type\": \"code\", \"execution_count\": null, \"metadata\": {}, \"outputs\": [], \"source\": [\n",
    "    \"# User configuration\\n\",\n",
    "    \"GCP_PROJECT_ID = 'YOUR_GCP_PROJECT'  # <-- set this\\n\",\n",
    "    \"INITIAL_COHORT_CSV = os.path.join('project','data','initial_cohort.csv')  # must contain subject_id\\n\",\n",
    "    \"LABELS_CSV = None  # if provided, skip generation; must have subject_id + *_label columns\\n\",\n",
    "    \"GENERATE_LABELS = True  # build labels if LABELS_CSV is None\\n\",\n",
    "    \"OUTPUT_MODELS_DIR = os.path.join('project','models')\\n\",\n",
    "    \"TEST_SIZE = 0.2\\n\",\n",
    "    \"RANDOM_STATE = 42\\n\",\n",
    "    \"GCP_PROJECT_ID, INITIAL_COHORT_CSV, LABELS_CSV, GENERATE_LABELS\"\n",
    "  ]},\n",
    "  {\"cell_type\": \"code\", \"execution_count\": null, \"metadata\": {}, \"outputs\": [], \"source\": [\n",
    "    \"# Load cohort & init BigQuery client\\n\",\n",
    "    \"from google.cloud import bigquery\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"if not os.path.exists(INITIAL_COHORT_CSV):\\n\",\n",
    "    \"    raise FileNotFoundError(f'Missing cohort CSV: {INITIAL_COHORT_CSV}')\\n\",\n",
    "    \"cohort_df = pd.read_csv(INITIAL_COHORT_CSV)\\n\",\n",
    "    \"if 'subject_id' not in cohort_df.columns:\\n\",\n",
    "    \"    raise ValueError('INITIAL_COHORT_CSV must contain subject_id')\\n\",\n",
    "    \"subject_ids = cohort_df['subject_id'].dropna().astype(int).tolist()\\n\",\n",
    "    \"print(f'Cohort size: {len(subject_ids)}')\\n\",\n",
    "    \"bq_client = bigquery.Client(project=GCP_PROJECT_ID)\\n\",\n",
    "    \"print('BigQuery client ready.')\\n\"\n",
    "  ]},\n",
    "  {\"cell_type\": \"code\", \"execution_count\": null, \"metadata\": {}, \"outputs\": [], \"source\": [\n",
    "    \"# Build labels if needed\\n\",\n",
    "    \"import datetime as _dt\\n\",\n",
    "    \"if LABELS_CSV is None and GENERATE_LABELS:\\n\",\n",
    "    \"    from project.labels import build_and_save_labels\\n\",\n",
    "    \"    ts = _dt.datetime.utcnow().strftime('%Y%m%d_%H%M%S')\\n\",\n",
    "    \"    LABELS_CSV = os.path.join('project','data', f'labels_generated_{ts}.csv')\\n\",\n",
    "    \"    labels_df = build_and_save_labels(bq_client, subject_ids, LABELS_CSV)\\n\",\n",
    "    \"    print(f'Generated labels file: {LABELS_CSV} (n={len(labels_df)})')\\n\",\n",
    "    \"elif LABELS_CSV is not None:\\n\",\n",
    "    \"    if not os.path.exists(LABELS_CSV):\\n\",\n",
    "    \"        raise FileNotFoundError(f'Provided LABELS_CSV not found: {LABELS_CSV}')\\n\",\n",
    "    \"    labels_df = pd.read_csv(LABELS_CSV)\\n\",\n",
    "    \"    print(f'Loaded existing labels (n={len(labels_df)})')\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    raise ValueError('LABELS_CSV is None and GENERATE_LABELS is False -> nothing to train.')\\n\",\n",
    "    \"labels_df.head()\"\n",
    "  ]},\n",
    "  {\"cell_type\": \"code\", \"execution_count\": null, \"metadata\": {}, \"outputs\": [], \"source\": [\n",
    "    \"# Train models\\n\",\n",
    "    \"from project.train import train_from_labels\\n\",\n",
    "    \"metrics = train_from_labels(GCP_PROJECT_ID, LABELS_CSV, OUTPUT_MODELS_DIR, test_size=TEST_SIZE, random_state=RANDOM_STATE)\\n\",\n",
    "    \"print('Training complete. Metrics summary below:')\\n\",\n",
    "    \"metrics\"\n",
    "  ]},\n",
    "  {\"cell_type\": \"code\", \"execution_count\": null, \"metadata\": {}, \"outputs\": [], \"source\": [\n",
    "    \"# Inspect saved artifacts\\n\",\n",
    "    \"import json, glob\\n\",\n",
    "    \"print('Models directory contents:')\\n\",\n",
    "    \"for fp in glob.glob(OUTPUT_MODELS_DIR + os.sep + '*'):\\n\",\n",
    "    \"    print(' -', os.path.basename(fp))\\n\",\n",
    "    \"metrics_path = os.path.join(OUTPUT_MODELS_DIR, 'metrics.json')\\n\",\n",
    "    \"if os.path.exists(metrics_path):\\n\",\n",
    "    \"    print('\\nmetrics.json:')\\n\",\n",
    "    \"    print(open(metrics_path,'r',encoding='utf-8').read())\\n\"\n",
    "  ]}\n",
    " ],\n",
    " \"metadata\": {\"kernelspec\": {\"display_name\": \"Python 3\", \"language\": \"python\", \"name\": \"python3\"}, \"language_info\": {\"name\": \"python\", \"version\": \"3\"}},\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 5\n",
    "}\n"
   ],
   "id": "f50582c5233013f6"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
