{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "791201e3",
   "metadata": {},
   "source": [
    "End-to-end (current focus: Readmission with XGBoost + Optuna). Structure prepared for mortality & prolonged LOS later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e63c1e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: c:\\Users\\Almog Luz\\Documents\\GitHub\\mlhc-final-project\\project\n",
      "Data dir exists: True\n",
      "Versions: {\n",
      "  \"python\": \"3.13.3\",\n",
      "  \"platform\": \"Windows-10-10.0.19045-SP0\",\n",
      "  \"xgboost\": \"2.1.1\",\n",
      "  \"optuna\": \"4.5.0\",\n",
      "  \"shap\": \"0.48.0\",\n",
      "  \"sklearn\": \"1.7.1\",\n",
      "  \"pandas\": \"2.3.1\",\n",
      "  \"numpy\": \"2.2.6\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Environment & core imports\n",
    "import os, sys, json, random, platform, importlib, datetime\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED)\n",
    "PROJECT_ROOT = (Path.cwd().parent if Path.cwd().name == 'notebooks' else Path.cwd())\n",
    "DATA_DIR = PROJECT_ROOT / 'data'\n",
    "ARTIFACTS_DIR = PROJECT_ROOT / 'artifacts'\n",
    "RUNS_ROOT = PROJECT_ROOT / 'runs'\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"Data dir exists: {(DATA_DIR).exists()}\")\n",
    "VERSIONS = {'python': sys.version.split()[0], 'platform': platform.platform()}\n",
    "for pkg in ['xgboost','optuna','shap','sklearn','pandas','numpy']:\n",
    "    try:\n",
    "        m = importlib.import_module(pkg if pkg != 'sklearn' else 'sklearn')\n",
    "        VERSIONS[pkg] = getattr(m,'__version__','?')\n",
    "    except Exception as e:\n",
    "        VERSIONS[pkg] = f'NA({e})'\n",
    "print('Versions:', json.dumps(VERSIONS, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c560f373",
   "metadata": {},
   "source": [
    "### Labels\n",
    "Load readmission labels (or synthesize) and report prevalence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17c3dfd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels source: c:\\Users\\Almog Luz\\Documents\\GitHub\\mlhc-final-project\\project\\data\\labels.csv | shape=(28473, 5) | prevalence=0.0433\n"
     ]
    }
   ],
   "source": [
    "# Load or generate labels (readmission focus)\n",
    "import pandas as pd, random\n",
    "LABELS_PATH = None\n",
    "LABEL_CANDIDATES = [DATA_DIR / 'labels.csv', PROJECT_ROOT / 'labels.csv']\n",
    "for cand in LABEL_CANDIDATES:\n",
    "    if cand.exists():\n",
    "        LABELS_PATH = cand\n",
    "        break\n",
    "labels_df = None\n",
    "if LABELS_PATH is not None:\n",
    "    labels_df = pd.read_csv(LABELS_PATH)\n",
    "else:\n",
    "    cohort_path = DATA_DIR / 'initial_cohort.csv'\n",
    "    if not cohort_path.exists():\n",
    "        raise FileNotFoundError('initial_cohort.csv missing; cannot synthesize labels')\n",
    "    subj = pd.read_csv(cohort_path)\n",
    "    random.seed(SEED)\n",
    "    synth = pd.Series([1 if random.random() < 0.043 else 0 for _ in range(len(subj))])\n",
    "    labels_df = pd.DataFrame({'subject_id': subj['subject_id'],'hadm_id': -1,'readmission_label': synth.values})\n",
    "    LABELS_PATH = '<synthetic>'\n",
    "# Normalize column name\n",
    "if 'readmission_label' not in labels_df.columns:\n",
    "    lower_map = {c.lower(): c for c in labels_df.columns}\n",
    "    for alias in ['readmission_label','readmission','readmit','readmit_30d','readmission_30d']:\n",
    "        if alias in lower_map:\n",
    "            if lower_map[alias] != 'readmission_label':\n",
    "                labels_df.rename(columns={lower_map[alias]:'readmission_label'}, inplace=True)\n",
    "            break\n",
    "if 'readmission_label' not in labels_df.columns:\n",
    "    raise ValueError('Could not identify readmission label column')\n",
    "labels_df = labels_df.drop_duplicates('subject_id')\n",
    "labels_df['readmission_label'] = labels_df['readmission_label'].astype(int)\n",
    "assert labels_df['subject_id'].isna().sum()==0\n",
    "prev = labels_df['readmission_label'].mean()\n",
    "print(f\"Labels source: {LABELS_PATH} | shape={labels_df.shape} | prevalence={prev:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d4f32a",
   "metadata": {},
   "source": [
    "### Features\n",
    "Load (or regenerate) prepared feature matrix aligned to subjects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65c9d838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features loaded shape: (28473, 1429) \n"
     ]
    }
   ],
   "source": [
    "# Load feature matrix (regenerate if tiny/corrupt)\n",
    "import pandas as pd, json, hashlib\n",
    "feature_path = ARTIFACTS_DIR / 'features_full.parquet'\n",
    "regenerated = False\n",
    "if feature_path.exists() and feature_path.stat().st_size < 1000:\n",
    "    print('Corrupted feature parquet detected; attempting regeneration.')\n",
    "    cache_dir = DATA_DIR / 'extracted_cache'\n",
    "    try:\n",
    "        from src.features import build_features, build_feature_provenance  # type: ignore\n",
    "        def load_opt(name):\n",
    "            p = cache_dir / name\n",
    "            return pd.read_parquet(p) if p.exists() else None\n",
    "        demo = load_opt('demographics.parquet')\n",
    "        first_adm = load_opt('first_admissions.parquet')\n",
    "        vitals = load_opt('vitals_48h.parquet')\n",
    "        labs = load_opt('labs_48h.parquet')\n",
    "        rx = load_opt('prescriptions_48h.parquet')\n",
    "        proc = load_opt('procedures_48h.parquet')\n",
    "        feats = build_features(first_adm, demo, vitals, labs, rx, proc)\n",
    "        feats = feats.reindex(labels_df['subject_id']).fillna(0.0)\n",
    "        feats.to_parquet(feature_path)\n",
    "        prov = build_feature_provenance(feats)\n",
    "        (ARTIFACTS_DIR / 'feature_provenance.json').write_text(json.dumps(prov, indent=2))\n",
    "        (ARTIFACTS_DIR / 'feature_columns.json').write_text(json.dumps(list(feats.columns)))\n",
    "        regenerated = True\n",
    "        print('Regenerated features:', feats.shape)\n",
    "    except Exception as e:\n",
    "        print('Feature regeneration failed:', e)\n",
    "if not feature_path.exists():\n",
    "    raise FileNotFoundError(f'Missing {feature_path}; ensure extraction step executed.')\n",
    "feature_df = pd.read_parquet(feature_path)\n",
    "if 'subject_id' in feature_df.columns:\n",
    "    feature_df = feature_df.set_index('subject_id')\n",
    "feature_df = feature_df.reindex(labels_df['subject_id']).fillna(0.0)\n",
    "print('Features loaded shape:', feature_df.shape, '| regenerated' if regenerated else '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa08550",
   "metadata": {},
   "source": [
    "### Train/Validation/Test Split\n",
    "Create 60/20/20 stratified split and compute imbalance weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d05e9534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split -> train (17083, 1429) valid (5695, 1429) test (5695, 1429) | pos_rate_train=0.0433 | spw≈22.12\n"
     ]
    }
   ],
   "source": [
    "# Train/valid/test split (60/20/20) + class weight factor\n",
    "from sklearn.model_selection import train_test_split\n",
    "readmit_y = labels_df['readmission_label'].astype(int).to_numpy()\n",
    "subject_index = feature_df.index.to_numpy()\n",
    "X = feature_df.values\n",
    "X_tr, X_temp, y_tr, y_temp, sid_tr, sid_temp = train_test_split(\n",
    "    X, readmit_y, subject_index, test_size=0.4, stratify=readmit_y, random_state=SEED)\n",
    "X_val, X_te, y_val, y_te, sid_val, sid_te = train_test_split(\n",
    "    X_temp, y_temp, sid_temp, test_size=0.5, stratify=y_temp, random_state=SEED)\n",
    "pos_rate = y_tr.mean(); scale_pos_weight = (1-pos_rate)/max(pos_rate,1e-6)\n",
    "print(f'Split -> train {X_tr.shape} valid {X_val.shape} test {X_te.shape} | pos_rate_train={pos_rate:.4f} | spw≈{scale_pos_weight:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281cc739",
   "metadata": {},
   "source": [
    "### Metrics Helpers\n",
    "Utility functions to compute threshold-dependent metrics and cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cfb41202",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score, f1_score, confusion_matrix\n",
    "import numpy as np\n",
    "C_FP = 1.0; C_FN = 5.0\n",
    "beta = 2.0\n",
    "\n",
    "def metrics_at(proba, y, thr):\n",
    "    pred = (proba >= thr).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y, pred).ravel()\n",
    "    cost = C_FP*fp + C_FN*fn\n",
    "    f1 = f1_score(y, pred)\n",
    "    prec = tp/(tp+fp+1e-9); rec = tp/(tp+fn+1e-9)\n",
    "    fbeta = (1+beta**2)*prec*rec/(beta**2*prec+rec+1e-9)\n",
    "    return dict(f1=f1, precision=prec, recall=rec, cost=cost, fbeta=fbeta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c159178",
   "metadata": {},
   "source": [
    "### Baseline Model\n",
    "Train a simple class-weighted logistic regression for reference AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b62e409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Logistic Validation AUC: 0.5811\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "baseline_pipe = Pipeline([\n",
    "    (\"imp\", SimpleImputer(strategy='median')),\n",
    "    (\"sc\", StandardScaler(with_mean=False)),\n",
    "    (\"lr\", LogisticRegression(max_iter=500, class_weight='balanced', solver='liblinear'))\n",
    "])\n",
    "baseline_pipe.fit(X_tr, y_tr)\n",
    "baseline_val_proba = baseline_pipe.predict_proba(X_val)[:,1]\n",
    "baseline_auc = roc_auc_score(y_val, baseline_val_proba)\n",
    "print('Baseline Logistic Validation AUC:', round(baseline_auc,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "301d94cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-13 15:48:00,048] A new study created in memory with name: no-name-41c50ae1-356b-4146-b359-b33331652ed2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study created.\n"
     ]
    }
   ],
   "source": [
    "import optuna, xgboost as xgb\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.pruners import MedianPruner\n",
    "study = optuna.create_study(direction='maximize', sampler=TPESampler(seed=SEED), pruner=MedianPruner())\n",
    "print('Study created.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f79cc9b",
   "metadata": {},
   "source": [
    "### Objective Definition\n",
    "Define Optuna objective: 5-fold stratified CV with early stopping (mean validation AUC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7b88eeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna objective: 5-fold stratified CV AUC (lightweight) using sklearn XGBClassifier\n",
    "# Performance tweaks: lower max n_estimators, optional row subsampling per fold for speed.\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "MAX_ROUNDS = 400  # reduced for speed since no early stopping\n",
    "N_FOLDS = 5\n",
    "SPEED_SAMPLE_MAX = 12000  # cap rows per fold training subset for speed\n",
    "\n",
    "\n",
    "def objective(trial: optuna.Trial):\n",
    "    params = {\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 7),\n",
    "        'min_child_weight': trial.suggest_float('min_child_weight', 1.0, 8.0),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'reg_lambda': trial.suggest_float('lambda', 1e-3, 5.0, log=True),\n",
    "        'reg_alpha': trial.suggest_float('alpha', 1e-3, 2.0, log=True),\n",
    "        'gamma': trial.suggest_float('gamma', 0.0, 4.0),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 120, MAX_ROUNDS),\n",
    "    }\n",
    "    fold_aucs = []\n",
    "    rng_local = np.random.default_rng(SEED + trial.number)\n",
    "    skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
    "    for fold, (tr_idx, va_idx) in enumerate(skf.split(X_tr, y_tr), 1):\n",
    "        Xtr_f, Xva_f = X_tr[tr_idx], X_tr[va_idx]\n",
    "        ytr_f, yva_f = y_tr[tr_idx], y_tr[va_idx]\n",
    "        # Speed row subsample (stratified) if oversized\n",
    "        if Xtr_f.shape[0] > SPEED_SAMPLE_MAX:\n",
    "            pos_idx = np.where(ytr_f==1)[0]\n",
    "            neg_idx = np.where(ytr_f==0)[0]\n",
    "            # keep all positives to maintain signal if rare\n",
    "            keep_pos = pos_idx\n",
    "            # sample negatives to reach SPEED_SAMPLE_MAX total\n",
    "            remaining = SPEED_SAMPLE_MAX - len(keep_pos)\n",
    "            if remaining < len(neg_idx):\n",
    "                keep_neg = rng_local.choice(neg_idx, size=remaining, replace=False)\n",
    "            else:\n",
    "                keep_neg = neg_idx\n",
    "            keep = np.concatenate([keep_pos, keep_neg])\n",
    "            rng_local.shuffle(keep)\n",
    "            Xtr_f = Xtr_f[keep]\n",
    "            ytr_f = ytr_f[keep]\n",
    "        model = XGBClassifier(\n",
    "            objective='binary:logistic', tree_method='hist',\n",
    "            scale_pos_weight=scale_pos_weight, eval_metric='auc',\n",
    "            verbosity=0, **params\n",
    "        )\n",
    "        model.fit(Xtr_f, ytr_f, verbose=False)\n",
    "        proba = model.predict_proba(Xva_f)[:,1]\n",
    "        fold_auc = roc_auc_score(yva_f, proba)\n",
    "        fold_aucs.append(fold_auc)\n",
    "    mean_auc = float(np.mean(fold_aucs))\n",
    "    trial.set_user_attr('fold_aucs', fold_aucs)\n",
    "    trial.set_user_attr('cv_mean_auc', mean_auc)\n",
    "    return mean_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ae8d32",
   "metadata": {},
   "source": [
    "### Run Hyperparameter Search\n",
    "Execute trials optimizing mean 5-fold CV AUC (early stopping each fold)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6d964627",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-13 16:21:43,841] Trial 13 finished with value: 0.6222714796987352 and parameters: {'learning_rate': 0.010196893017132471, 'max_depth': 6, 'min_child_weight': 7.788405875023145, 'subsample': 0.7471244966734023, 'colsample_bytree': 0.9963583331053159, 'lambda': 0.14565654991219462, 'alpha': 0.11799624551738404, 'gamma': 2.585651259188504, 'n_estimators': 123}. Best is trial 4 with value: 0.6274018529118605.\n",
      "[I 2025-09-13 16:22:02,304] Trial 14 finished with value: 0.6228481171309606 and parameters: {'learning_rate': 0.015529361529665643, 'max_depth': 5, 'min_child_weight': 4.1958034965567395, 'subsample': 0.7146484682094928, 'colsample_bytree': 0.9893673051130601, 'lambda': 0.19511174188897631, 'alpha': 0.0062716249528685115, 'gamma': 2.5691150354358707, 'n_estimators': 129}. Best is trial 4 with value: 0.6274018529118605.\n",
      "[I 2025-09-13 16:22:02,304] Trial 14 finished with value: 0.6228481171309606 and parameters: {'learning_rate': 0.015529361529665643, 'max_depth': 5, 'min_child_weight': 4.1958034965567395, 'subsample': 0.7146484682094928, 'colsample_bytree': 0.9893673051130601, 'lambda': 0.19511174188897631, 'alpha': 0.0062716249528685115, 'gamma': 2.5691150354358707, 'n_estimators': 129}. Best is trial 4 with value: 0.6274018529118605.\n",
      "[I 2025-09-13 16:22:22,211] Trial 15 finished with value: 0.61639507956797 and parameters: {'learning_rate': 0.019038142108351763, 'max_depth': 5, 'min_child_weight': 4.234803308807896, 'subsample': 0.9984067957444853, 'colsample_bytree': 0.7576919173357378, 'lambda': 0.3564740897355612, 'alpha': 0.001182372154756648, 'gamma': 2.9505784285571846, 'n_estimators': 143}. Best is trial 4 with value: 0.6274018529118605.\n",
      "[I 2025-09-13 16:22:22,211] Trial 15 finished with value: 0.61639507956797 and parameters: {'learning_rate': 0.019038142108351763, 'max_depth': 5, 'min_child_weight': 4.234803308807896, 'subsample': 0.9984067957444853, 'colsample_bytree': 0.7576919173357378, 'lambda': 0.3564740897355612, 'alpha': 0.001182372154756648, 'gamma': 2.9505784285571846, 'n_estimators': 143}. Best is trial 4 with value: 0.6274018529118605.\n",
      "[I 2025-09-13 16:22:47,597] Trial 16 finished with value: 0.6246608750790238 and parameters: {'learning_rate': 0.015894077583837568, 'max_depth': 5, 'min_child_weight': 3.0153650962554495, 'subsample': 0.703538203412569, 'colsample_bytree': 0.9801061135144897, 'lambda': 2.096043753246458, 'alpha': 0.0060663318382331065, 'gamma': 0.06204152797690843, 'n_estimators': 174}. Best is trial 4 with value: 0.6274018529118605.\n",
      "[I 2025-09-13 16:22:47,597] Trial 16 finished with value: 0.6246608750790238 and parameters: {'learning_rate': 0.015894077583837568, 'max_depth': 5, 'min_child_weight': 3.0153650962554495, 'subsample': 0.703538203412569, 'colsample_bytree': 0.9801061135144897, 'lambda': 2.096043753246458, 'alpha': 0.0060663318382331065, 'gamma': 0.06204152797690843, 'n_estimators': 174}. Best is trial 4 with value: 0.6274018529118605.\n",
      "[I 2025-09-13 16:23:08,655] Trial 17 finished with value: 0.6046227825183487 and parameters: {'learning_rate': 0.09549603149038433, 'max_depth': 3, 'min_child_weight': 2.8934095572196292, 'subsample': 0.6618897082112803, 'colsample_bytree': 0.8250051428101366, 'lambda': 2.5270749522610076, 'alpha': 0.004343867993810019, 'gamma': 0.108876105564788, 'n_estimators': 187}. Best is trial 4 with value: 0.6274018529118605.\n",
      "[I 2025-09-13 16:23:08,655] Trial 17 finished with value: 0.6046227825183487 and parameters: {'learning_rate': 0.09549603149038433, 'max_depth': 3, 'min_child_weight': 2.8934095572196292, 'subsample': 0.6618897082112803, 'colsample_bytree': 0.8250051428101366, 'lambda': 2.5270749522610076, 'alpha': 0.004343867993810019, 'gamma': 0.108876105564788, 'n_estimators': 187}. Best is trial 4 with value: 0.6274018529118605.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best AUC: 0.6274018529118605\n",
      "Best Params: {'learning_rate': 0.015380821666156693, 'max_depth': 3, 'min_child_weight': 7.158097238609412, 'subsample': 0.7200762468698007, 'colsample_bytree': 0.5610191174223894, 'lambda': 0.09565499215943825, 'alpha': 0.0013403002793227008, 'gamma': 4.546602010393911, 'n_estimators': 533}\n"
     ]
    }
   ],
   "source": [
    "N_TRIALS = 5  # adjust upward for thorough search\n",
    "study.optimize(objective, n_trials=N_TRIALS, show_progress_bar=False)\n",
    "print('Best AUC:', study.best_value)\n",
    "print('Best Params:', study.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed5bedf",
   "metadata": {},
   "source": [
    "### Inspect Trials\n",
    "Overview of trials and (optional) optimization history plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16676a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_df = study.trials_dataframe()\n",
    "print('Trials:', trials_df.shape)\n",
    "try:\n",
    "    optuna.visualization.plot_optimization_history(study)\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b693a61",
   "metadata": {},
   "source": [
    "### Final Model Training\n",
    "Train final booster on combined train+validation using best params."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7400eecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final XGBClassifier trained (sklearn API, DataFrame/array based).\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "# Combine train+validation for final model used for raw probability generation (before calibration)\n",
    "X_tr_full = np.vstack([X_tr, X_val])\n",
    "y_tr_full = np.concatenate([y_tr, y_val])\n",
    "params = study.best_params.copy()\n",
    "final_model = XGBClassifier(\n",
    "    objective='binary:logistic', tree_method='hist',\n",
    "    learning_rate=params['learning_rate'],\n",
    "    n_estimators=params['n_estimators'],\n",
    "    max_depth=params['max_depth'],\n",
    "    min_child_weight=params['min_child_weight'],\n",
    "    subsample=params['subsample'],\n",
    "    colsample_bytree=params['colsample_bytree'],\n",
    "    reg_lambda=params['lambda'],\n",
    "    reg_alpha=params['alpha'],\n",
    "    gamma=params['gamma'],\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    eval_metric='auc',\n",
    "    verbosity=0\n",
    ")\n",
    "final_model.fit(X_tr_full, y_tr_full)\n",
    "print('Final XGBClassifier trained (sklearn API, DataFrame/array based).')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432add8f",
   "metadata": {},
   "source": [
    "### Calibration & Threshold\n",
    "Fit isotonic on validation; pick F1-optimal threshold on calibrated validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "612ab5ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Isotonic calibration fitted on validation set.\n",
      "Selected threshold (calibrated validation): {'f1': 0.1557377049180328, 'precision': np.float64(0.11752577319563397), 'recall': np.float64(0.2307692307682965), 'cost': np.float64(1378.0), 'fbeta': np.float64(0.19348268811432212), 'threshold': 0.0665551839464883}\n",
      "Selected threshold (calibrated validation): {'f1': 0.1557377049180328, 'precision': np.float64(0.11752577319563397), 'recall': np.float64(0.2307692307682965), 'cost': np.float64(1378.0), 'fbeta': np.float64(0.19348268811432212), 'threshold': 0.0665551839464883}\n"
     ]
    }
   ],
   "source": [
    "# Manual isotonic calibration (sklearn XGBClassifier base, no DMatrix)\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "import numpy as np\n",
    "\n",
    "# Base model: train-only (exclude validation for calibration fairness)\n",
    "params = study.best_params.copy()\n",
    "base_model = XGBClassifier(\n",
    "    objective='binary:logistic', tree_method='hist',\n",
    "    learning_rate=params['learning_rate'],\n",
    "    n_estimators=params['n_estimators'],\n",
    "    max_depth=params['max_depth'],\n",
    "    min_child_weight=params['min_child_weight'],\n",
    "    subsample=params['subsample'],\n",
    "    colsample_bytree=params['colsample_bytree'],\n",
    "    reg_lambda=params['lambda'],\n",
    "    reg_alpha=params['alpha'],\n",
    "    gamma=params['gamma'],\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    eval_metric='logloss',\n",
    "    verbosity=0\n",
    ")\n",
    "base_model.fit(X_tr, y_tr)\n",
    "val_proba_raw = base_model.predict_proba(X_val)[:,1]\n",
    "iso = IsotonicRegression(out_of_bounds='clip')\n",
    "iso.fit(val_proba_raw, y_val)\n",
    "print('Isotonic calibration fitted on validation set.')\n",
    "\n",
    "def predict_calibrated(X):\n",
    "    return iso.transform(base_model.predict_proba(X)[:,1])\n",
    "\n",
    "# Derive operating threshold on calibrated validation probabilities\n",
    "val_cal = predict_calibrated(X_val)\n",
    "ths = np.linspace(0.01,0.9,300)\n",
    "threshold_info = None\n",
    "for t in ths:\n",
    "    m = metrics_at(val_cal, y_val, t)\n",
    "    if (threshold_info is None) or (m['f1'] > threshold_info['f1']):\n",
    "        threshold_info = {**m, 'threshold': float(t)}\n",
    "print('Selected threshold (calibrated validation):', threshold_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5844e92f",
   "metadata": {},
   "source": [
    "### Test Evaluation\n",
    "Apply calibrated model + selected threshold; report core metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fadd9c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"auc\": 0.6049995001693457,\n",
      "  \"pr_auc\": 0.05755169256503535,\n",
      "  \"brier\": 0.04140597358729218,\n",
      "  \"threshold\": 0.0665551839464883,\n",
      "  \"f1_at_threshold\": 0.08743169398907104,\n",
      "  \"precision_at_threshold\": 0.06584362139904147,\n",
      "  \"recall_at_threshold\": 0.13008130081247934,\n",
      "  \"cost_at_threshold\": 1524.0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate calibrated model on test set\n",
    "from sklearn.metrics import brier_score_loss\n",
    "import json\n",
    "cal_proba_test = predict_calibrated(X_te)\n",
    "auc = roc_auc_score(y_te, cal_proba_test)\n",
    "pr = average_precision_score(y_te, cal_proba_test)\n",
    "brier = brier_score_loss(y_te, cal_proba_test)\n",
    "thr = threshold_info['threshold']\n",
    "th_metrics = metrics_at(cal_proba_test, y_te, thr)\n",
    "report = {\n",
    "    'auc': float(auc),\n",
    "    'pr_auc': float(pr),\n",
    "    'brier': float(brier),\n",
    "    'threshold': float(thr),\n",
    "    'f1_at_threshold': float(th_metrics['f1']),\n",
    "    'precision_at_threshold': float(th_metrics['precision']),\n",
    "    'recall_at_threshold': float(th_metrics['recall']),\n",
    "    'cost_at_threshold': float(th_metrics['cost']),\n",
    "}\n",
    "print(json.dumps(report, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d03cc3e",
   "metadata": {},
   "source": [
    "### SHAP Summary\n",
    "Compute SHAP values on a sample for global importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f76582e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top SHAP feature indices (first 10 of 20): [  25  170  625    6 1169  455 1345 1014   95 1005]\n"
     ]
    }
   ],
   "source": [
    "# SHAP global explanation (sample subset) using base_model\n",
    "import numpy as np\n",
    "try:\n",
    "    import shap\n",
    "    X_tr_full = np.vstack([X_tr, X_val])\n",
    "    sample_idx = np.random.RandomState(42).choice(X_tr_full.shape[0], size=min(400, X_tr_full.shape[0]), replace=False)\n",
    "    X_sample = X_tr_full[sample_idx]\n",
    "    explainer = shap.TreeExplainer(base_model)\n",
    "    shap_val = explainer.shap_values(X_sample)\n",
    "    mean_abs = np.abs(shap_val).mean(axis=0)\n",
    "    top_order = np.argsort(-mean_abs)[:20]\n",
    "    print('Top SHAP feature indices (first 10 of 20):', top_order[:10])\n",
    "except Exception as e:\n",
    "    print('SHAP skipped:', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c36d889",
   "metadata": {},
   "source": [
    "### Bootstrap AUC CI\n",
    "Estimate uncertainty of test ROC AUC via stratified bootstrap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "80eaa6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC bootstrap mean=0.6050 95% CI=(0.5730,0.6390) n=1000\n"
     ]
    }
   ],
   "source": [
    "# Bootstrap 95% CI for test AUC\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "R = 1000\n",
    "rng = np.random.default_rng(42)\n",
    "auc_samples = []\n",
    "for _ in range(R):\n",
    "    idx_pos = np.where(y_te==1)[0]\n",
    "    idx_neg = np.where(y_te==0)[0]\n",
    "    b_pos = rng.choice(idx_pos, size=len(idx_pos), replace=True)\n",
    "    b_neg = rng.choice(idx_neg, size=len(idx_neg), replace=True)\n",
    "    b_idx = np.concatenate([b_pos, b_neg])\n",
    "    auc_samples.append(roc_auc_score(y_te[b_idx], cal_proba_test[b_idx]))\n",
    "auc_samples = np.array(auc_samples)\n",
    "ci_low, ci_high = np.percentile(auc_samples, [2.5,97.5])\n",
    "print(f'AUC bootstrap mean={auc_samples.mean():.4f} 95% CI=({ci_low:.4f},{ci_high:.4f}) n={R}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b90e623",
   "metadata": {},
   "source": [
    "### Cross-Validation Summary\n",
    "Single consolidated cell: reuse Optuna best-trial fold AUCs + compute logistic regression 5-fold CV for uplift comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104d057d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV AUC Logistic: mean 0.5872 ± 0.0257\n",
      "CV AUC XGB     : mean 0.6348 ± 0.0154\n"
     ]
    }
   ],
   "source": [
    "# Consolidated CV summary: XGB folds from best Optuna trial + new logistic CV\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Extract XGB fold AUCs stored during tuning\n",
    "best_trial = study.best_trial\n",
    "xgb_fold_aucs = best_trial.user_attrs.get('fold_aucs', [])\n",
    "xgb_mean = float(np.mean(xgb_fold_aucs)) if xgb_fold_aucs else float('nan')\n",
    "xgb_std = float(np.std(xgb_fold_aucs)) if xgb_fold_aucs else float('nan')\n",
    "\n",
    "# Logistic CV on same combined train+validation set for contrast\n",
    "X_cv = np.vstack([X_tr, X_val])\n",
    "y_cv = np.concatenate([y_tr, y_val])\n",
    "log_skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "log_aucs = []\n",
    "for fold,(tr_idx, va_idx) in enumerate(log_skf.split(X_cv, y_cv), 1):\n",
    "    Xtr, Xva = X_cv[tr_idx], X_cv[va_idx]; ytr, yva = y_cv[tr_idx], y_cv[va_idx]\n",
    "    lr_pipe = Pipeline([\n",
    "        ('imp', SimpleImputer(strategy='median')),\n",
    "        ('sc', StandardScaler(with_mean=False)),\n",
    "        ('lr', LogisticRegression(max_iter=500, class_weight='balanced', solver='liblinear'))\n",
    "    ])\n",
    "    lr_pipe.fit(Xtr, ytr)\n",
    "    log_aucs.append(roc_auc_score(yva, lr_pipe.predict_proba(Xva)[:,1]))\n",
    "log_mean = float(np.mean(log_aucs)); log_std = float(np.std(log_aucs))\n",
    "\n",
    "print('XGB CV AUCs (best trial):', [round(a,4) for a in xgb_fold_aucs])\n",
    "print(f'XGB CV mean ± std: {xgb_mean:.4f} ± {xgb_std:.4f}')\n",
    "print('Logistic CV AUCs:', [round(a,4) for a in log_aucs])\n",
    "print(f'Logistic CV mean ± std: {log_mean:.4f} ± {log_std:.4f}')\n",
    "\n",
    "# Optional uplift summary\n",
    "if xgb_mean == xgb_mean and log_mean == log_mean:  # not NaN\n",
    "    uplift = xgb_mean - log_mean\n",
    "    print(f'Uplift (XGB - Logistic) mean AUC: {uplift:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b07989",
   "metadata": {},
   "source": [
    "### Persist Artifacts\n",
    "Save model, calibration objects, metrics, threshold, and metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e8520590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifacts saved -> c:\\Users\\Almog Luz\\Documents\\GitHub\\mlhc-final-project\\project\\artifacts\n"
     ]
    }
   ],
   "source": [
    "# Persist artifacts (sklearn XGBClassifier + calibration + metadata)\n",
    "import json, joblib, hashlib, time, subprocess\n",
    "OUT_DIR = ARTIFACTS_DIR\n",
    "OUT_DIR.mkdir(exist_ok=True)\n",
    "joblib.dump(base_model, OUT_DIR / 'model_readmission.joblib')\n",
    "joblib.dump(iso, OUT_DIR / 'isotonic.joblib')\n",
    "with open(OUT_DIR / 'best_params.json','w',encoding='utf-8') as f: json.dump(study.best_params, f, indent=2)\n",
    "with open(OUT_DIR / 'metrics.json','w',encoding='utf-8') as f: json.dump(report, f, indent=2)\n",
    "with open(OUT_DIR / 'threshold.txt','w') as f: f.write(str(report['threshold']))\n",
    "try:\n",
    "    git_commit = subprocess.check_output(['git','rev-parse','HEAD'], text=True).strip()\n",
    "except Exception:\n",
    "    git_commit = 'UNKNOWN'\n",
    "feat_cols = list(feature_df.columns)\n",
    "feat_sig = hashlib.sha256(('|'.join(feat_cols)).encode()).hexdigest()[:16]\n",
    "meta = {\n",
    "    'saved_utc': time.strftime('%Y-%m-%dT%H:%M:%SZ', time.gmtime()),\n",
    "    'git_commit': git_commit,\n",
    "    'n_features': len(feat_cols),\n",
    "    'feature_sig_sha256_16': feat_sig,\n",
    "    'prevalence_train': float(y_tr.mean()),\n",
    "    'prevalence_valid': float(y_val.mean()),\n",
    "    'prevalence_test': float(y_te.mean()),\n",
    "    'optuna_best_value': float(study.best_value),\n",
    "    'threshold_info': threshold_info,\n",
    "    'calibration': 'isotonic_on_validation',\n",
    "    'cv_folds_best_mean_auc': float(study.best_value)\n",
    "}\n",
    "with open(OUT_DIR / 'run_metadata.json','w',encoding='utf-8') as f: json.dump(meta, f, indent=2)\n",
    "print('Artifacts saved ->', OUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf753cc",
   "metadata": {},
   "source": [
    "### Experiment Registry\n",
    "Append current run metrics to CSV registry for tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4b5d599e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged metrics to c:\\Users\\Almog Luz\\Documents\\GitHub\\mlhc-final-project\\project\\experiment_registry.csv\n"
     ]
    }
   ],
   "source": [
    "# Append metrics to experiment registry\n",
    "import csv, time\n",
    "REG_PATH = PROJECT_ROOT / 'experiment_registry.csv'\n",
    "row = {'ts': time.time(), **report}\n",
    "write_header = not REG_PATH.exists()\n",
    "with open(REG_PATH,'a',newline='') as f:\n",
    "    w = csv.DictWriter(f, fieldnames=row.keys())\n",
    "    if write_header: w.writeheader()\n",
    "    w.writerow(row)\n",
    "print('Logged metrics to', REG_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa550ed7",
   "metadata": {},
   "source": [
    "### Single Prediction Demo\n",
    "Show calibrated probability for one test instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6a863509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single test example calibrated probability: 0.04131355881690979\n"
     ]
    }
   ],
   "source": [
    "# Single example calibrated probability demo (using base_model + iso)\n",
    "raw_proba = base_model.predict_proba(X_te[:1])[:,1][0]\n",
    "calib_proba = iso.transform([raw_proba])[0]\n",
    "print('Single test example calibrated probability:', float(calib_proba))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
