{
 "cells": [
  {
   "cell_type": "raw",
   "id": "f50582c5233013f6",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# MLHC: Lean Training Notebook\n",
    "\n",
    "Minimal end-to-end training: configure, (optionally) build labels, train models, inspect metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3707e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.path[0]= c:\\Users\\Almog Luz\\Documents\\GitHub\\mlhc-final-project\n"
     ]
    }
   ],
   "source": [
    "# Path setup so 'project' package imports regardless of IDE CWD\n",
    "import sys, os, pathlib\n",
    "cands = [pathlib.Path.cwd(), pathlib.Path.cwd().parent, pathlib.Path.cwd()/ 'project', pathlib.Path.cwd().parent / 'project']\n",
    "for p in cands:\n",
    "    if p.is_dir() and str(p) not in sys.path:\n",
    "        sys.path.insert(0, str(p))\n",
    "print('sys.path[0]=', sys.path[0])\n",
    "\n",
    "# (Inspection placeholder) retaining content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28605645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run ID: 20250905_141147\n",
      "Artifacts root: runs\\20250905_141147\n",
      "Models dir: runs\\20250905_141147\\models\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('ml-for-healthcare-2025',\n",
       " 'data/initial_cohort.csv',\n",
       " None,\n",
       " True,\n",
       " 'runs\\\\20250905_141147',\n",
       " 'runs\\\\20250905_141147\\\\models')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# User configuration\n",
    "import os, pathlib, datetime as _dt\n",
    "GCP_PROJECT_ID = 'ml-for-healthcare-2025'\n",
    "_COHORT_CANDIDATES = [\n",
    "    'data/initial_cohort.csv',\n",
    "    os.path.join('project','data','initial_cohort.csv'),\n",
    "    os.path.join('..','project','data','initial_cohort.csv'),\n",
    "]\n",
    "INITIAL_COHORT_CSV = next((c for c in _COHORT_CANDIDATES if os.path.exists(c)), _COHORT_CANDIDATES[0])\n",
    "LABELS_CSV = None\n",
    "GENERATE_LABELS = True\n",
    "RUN_ID = _dt.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "if os.path.basename(os.getcwd()) == 'project':\n",
    "    RUNS_ROOT = 'runs'\n",
    "elif os.path.isdir('project'):\n",
    "    RUNS_ROOT = os.path.join('project', 'runs')\n",
    "else:\n",
    "    RUNS_ROOT = 'runs'\n",
    "RUNS_ROOT = RUNS_ROOT.replace('project' + os.sep + 'project', 'project')\n",
    "ARTIFACTS_DIR = os.path.join(RUNS_ROOT, RUN_ID)\n",
    "OUTPUT_ARTIFACTS_DIR = os.path.join(ARTIFACTS_DIR,'artifacts')\n",
    "os.makedirs(OUTPUT_ARTIFACTS_DIR, exist_ok=True)\n",
    "os.environ['MLHC_ARTIFACTS_DIR'] = os.path.abspath(OUTPUT_ARTIFACTS_DIR)\n",
    "print(f'Run ID: {RUN_ID}')\n",
    "print('Artifacts root:', ARTIFACTS_DIR)\n",
    "print('Artifacts dir:', OUTPUT_ARTIFACTS_DIR)\n",
    "TEST_SIZE = 0.2\n",
    "RANDOM_STATE = 42\n",
    "GCP_PROJECT_ID, INITIAL_COHORT_CSV, LABELS_CSV, GENERATE_LABELS, ARTIFACTS_DIR, OUTPUT_ARTIFACTS_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7738617e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohort size: 32513 from data/initial_cohort.csv\n",
      "Saved cohort snapshot to runs\\20250905_141147\\data\\cohort_snapshot.csv\n",
      "BigQuery client ready.\n",
      "BigQuery client ready.\n"
     ]
    }
   ],
   "source": [
    "# Load cohort & init BigQuery client (robust path resolution)\n",
    "from google.cloud import bigquery\n",
    "import pandas as pd, json\n",
    "if not os.path.exists(INITIAL_COHORT_CSV):\n",
    "    raise FileNotFoundError(\n",
    "        'Missing cohort CSV. Looked for: ' + INITIAL_COHORT_CSV + '\\n'\n",
    "        'If running from repo root, set INITIAL_COHORT_CSV to project/data/initial_cohort.csv; '\n",
    "        'if running inside project/, set to data/initial_cohort.csv.'\n",
    "    )\n",
    "cohort_df = pd.read_csv(INITIAL_COHORT_CSV)\n",
    "if 'subject_id' not in cohort_df.columns:\n",
    "    raise ValueError('INITIAL_COHORT_CSV must contain subject_id')\n",
    "subject_ids = cohort_df['subject_id'].dropna().astype(int).tolist()\n",
    "print(f'Cohort size: {len(subject_ids)} from {INITIAL_COHORT_CSV}')\n",
    "os.makedirs(os.path.join(ARTIFACTS_DIR,'data'), exist_ok=True)\n",
    "cohort_copy_path = os.path.join(ARTIFACTS_DIR,'data','cohort_snapshot.csv')\n",
    "cohort_df.to_csv(cohort_copy_path, index=False)\n",
    "print('Saved cohort snapshot to', cohort_copy_path)\n",
    "try:\n",
    "    bq_client = bigquery.Client(project=GCP_PROJECT_ID)\n",
    "    print('BigQuery client ready.')\n",
    "except Exception as e:\n",
    "    bq_client = None\n",
    "    print('Warning: BigQuery client not initialized ->', e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a390a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated labels file: runs\\20250905_141147\\data\\labels.csv (n=28473)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "subject_id",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "hadm_id",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "mortality_label",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "prolonged_los_label",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "readmission_label",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "03e8bf75-87d4-4342-8020-38aa69d95a23",
       "rows": [
        [
         "0",
         "2",
         "163353",
         "0",
         "0",
         "0"
        ],
        [
         "1",
         "3",
         "145834",
         "0",
         "1",
         "0"
        ],
        [
         "2",
         "4",
         "185777",
         "0",
         "1",
         "0"
        ],
        [
         "3",
         "5",
         "178980",
         "0",
         "0",
         "0"
        ],
        [
         "4",
         "7",
         "118037",
         "0",
         "0",
         "0"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>mortality_label</th>\n",
       "      <th>prolonged_los_label</th>\n",
       "      <th>readmission_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>163353</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>145834</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>185777</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>178980</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>118037</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id  hadm_id  mortality_label  prolonged_los_label  \\\n",
       "0           2   163353                0                    0   \n",
       "1           3   145834                0                    1   \n",
       "2           4   185777                0                    1   \n",
       "3           5   178980                0                    0   \n",
       "4           7   118037                0                    0   \n",
       "\n",
       "   readmission_label  \n",
       "0                  0  \n",
       "1                  0  \n",
       "2                  0  \n",
       "3                  0  \n",
       "4                  0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build labels if needed (requires BigQuery access)\n",
    "import datetime as _dt\n",
    "if LABELS_CSV is None and GENERATE_LABELS:\n",
    "    if bq_client is None:\n",
    "        raise RuntimeError('Cannot generate labels without BigQuery client/auth. Provide LABELS_CSV instead.')\n",
    "    from project.labels import build_and_save_labels\n",
    "    os.makedirs(os.path.join(ARTIFACTS_DIR,'data'), exist_ok=True)\n",
    "    LABELS_CSV = os.path.join(ARTIFACTS_DIR,'data', 'labels.csv')\n",
    "    labels_df = build_and_save_labels(bq_client, subject_ids, LABELS_CSV)\n",
    "    print(f'Generated labels file: {LABELS_CSV} (n={len(labels_df)})')\n",
    "elif LABELS_CSV is not None:\n",
    "    if not os.path.exists(LABELS_CSV):\n",
    "        raise FileNotFoundError(f'Provided LABELS_CSV not found: {LABELS_CSV}')\n",
    "    labels_df = pd.read_csv(LABELS_CSV)\n",
    "    print(f'Loaded existing labels (n={len(labels_df)})')\n",
    "else:\n",
    "    raise ValueError('LABELS_CSV is None and GENERATE_LABELS is False -> nothing to train.')\n",
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e64ceee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloaded project.train from c:\\Users\\Almog Luz\\Documents\\GitHub\\mlhc-final-project\\project\\train.py\n",
      "First line of _fit_model(): def _fit_model(\n",
      "[1/5] Loading labels CSV ...\n",
      "Copied labels to c:\\Users\\Almog Luz\\Documents\\GitHub\\mlhc-final-project\\project\\runs\\20250905_141147\\labels.csv\n",
      "[2/5] Building / loading feature matrices ...\n",
      "[2/5] Building / loading feature matrices ...\n",
      "Loaded features from cache directory (skipped BigQuery): c:\\Users\\Almog Luz\\Documents\\GitHub\\mlhc-final-project\\project\\data\\extracted_cache\n",
      "Loaded features from cache directory (skipped BigQuery): c:\\Users\\Almog Luz\\Documents\\GitHub\\mlhc-final-project\\project\\data\\extracted_cache\n",
      "[3/5] Fitting preprocessing pipeline on 28473 patients x 1618 features ...\n",
      "[3/5] Fitting preprocessing pipeline on 28473 patients x 1618 features ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d391ad1ff7f54bc58850c67df01881d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[4/5] Training targets:   0%|          | 0/3 [00:00<?, ?model/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CalibratedClassifierCV(logreg) method=isotonic cv=5\n",
      "CalibratedClassifierCV(logreg) method=isotonic cv=5\n",
      "CalibratedClassifierCV(logreg) method=isotonic cv=5\n",
      "CalibratedClassifierCV(logreg) method=isotonic cv=5\n",
      "CalibratedClassifierCV(logreg) method=isotonic cv=5\n",
      "[5/5] Writing metrics.json\n",
      "\n",
      "=== STAGE TIMINGS (seconds) ===\n",
      "total                           217.017\n",
      "model_fit_readmission            84.501\n",
      "model_fit_mortality              50.707\n",
      "model_fit_prolonged_los          36.856\n",
      "feature_extraction_total         23.903\n",
      "metrics_mortality                 6.192\n",
      "metrics_prolonged_los             4.577\n",
      "metrics_readmission               3.569\n",
      "preprocessor_fit_transform        3.200\n",
      "split_readmission                 0.505\n",
      "split_mortality                   0.494\n",
      "split_prolonged_los               0.464\n",
      "plot_prolonged_los                0.257\n",
      "plot_readmission                  0.234\n",
      "plot_mortality                    0.227\n",
      "curves_prolonged_los              0.020\n",
      "curves_mortality                  0.017\n",
      "curves_readmission                0.016\n",
      "load_labels                       0.009\n",
      "\n",
      "Totals:\n",
      "model_fit_    172.064\n",
      "importance_     0.000\n",
      "curves_         0.053\n",
      "plot_           0.718\n",
      "Training complete. Metrics summary below (saved to runs\\20250905_141147\\models\\metrics.json ):\n",
      "[5/5] Writing metrics.json\n",
      "\n",
      "=== STAGE TIMINGS (seconds) ===\n",
      "total                           217.017\n",
      "model_fit_readmission            84.501\n",
      "model_fit_mortality              50.707\n",
      "model_fit_prolonged_los          36.856\n",
      "feature_extraction_total         23.903\n",
      "metrics_mortality                 6.192\n",
      "metrics_prolonged_los             4.577\n",
      "metrics_readmission               3.569\n",
      "preprocessor_fit_transform        3.200\n",
      "split_readmission                 0.505\n",
      "split_mortality                   0.494\n",
      "split_prolonged_los               0.464\n",
      "plot_prolonged_los                0.257\n",
      "plot_readmission                  0.234\n",
      "plot_mortality                    0.227\n",
      "curves_prolonged_los              0.020\n",
      "curves_mortality                  0.017\n",
      "curves_readmission                0.016\n",
      "load_labels                       0.009\n",
      "\n",
      "Totals:\n",
      "model_fit_    172.064\n",
      "importance_     0.000\n",
      "curves_         0.053\n",
      "plot_           0.718\n",
      "Training complete. Metrics summary below (saved to runs\\20250905_141147\\models\\metrics.json ):\n"
     ]
    }
   ],
   "source": [
    "# Train models (with diagnostic wrapper)\n",
    "import importlib, sys, os, glob, json, traceback\n",
    "if 'project.train' in sys.modules:\n",
    "    import project.train as _train_mod\n",
    "    importlib.reload(_train_mod)\n",
    "    print('Reloaded project.train from', _train_mod.__file__)\n",
    "else:\n",
    "    import project.train as _train_mod\n",
    "    print('Imported project.train from', _train_mod.__file__)\n",
    "from project.train import train_from_labels\n",
    "import inspect\n",
    "_fit_src = inspect.getsource(_train_mod._fit_model).splitlines()[0]\n",
    "print('First line of _fit_model():', _fit_src)\n",
    "PROFILE = True\n",
    "SKIP_IMPORTANCE = True\n",
    "MODEL_TYPE = 'logreg'\n",
    "CALIB_CV = 5\n",
    "CV_FOLDS = 0\n",
    "FINALIZE_MODE = False\n",
    "if FINALIZE_MODE:\n",
    "    SKIP_IMPORTANCE = False\n",
    "    print('[FINALIZE] Full calibration & permutation importance enabled.')\n",
    "if LABELS_CSV is None:\n",
    "    raise RuntimeError('LABELS_CSV is not set; cannot proceed with training.')\n",
    "try:\n",
    "    metrics = train_from_labels(\n",
    "        GCP_PROJECT_ID,\n",
    "        LABELS_CSV,\n",
    "        OUTPUT_ARTIFACTS_DIR,\n",
    "        test_size=TEST_SIZE,\n",
    "        random_state=RANDOM_STATE,\n",
    "        use_cache_first=True,\n",
    "        profile=PROFILE,\n",
    "        model_type=MODEL_TYPE,\n",
    "        calib_cv=CALIB_CV,\n",
    "        skip_importance=SKIP_IMPORTANCE,\n",
    "        cv_folds=CV_FOLDS,\n",
    "        finalize_mode=FINALIZE_MODE,\n",
    "    )\n",
    "    metrics_path = os.path.join(OUTPUT_ARTIFACTS_DIR, 'metrics.json')\n",
    "    print('Training complete. Metrics summary below (saved to', metrics_path, '):')\n",
    "    metrics\n",
    "except Exception as e:\n",
    "    print('Training failed:', type(e).__name__, str(e))\n",
    "    print('\\n=== TRACEBACK ===')\n",
    "    traceback.print_exc()\n",
    "    print('\\n=== ENV / PATH DIAGNOSTICS ===')\n",
    "    print('Working directory:', os.getcwd())\n",
    "    print('Existing cohort paths:')\n",
    "    for p in ['data/initial_cohort.csv','project/data/initial_cohort.csv','../project/data/initial_cohort.csv']:\n",
    "        print(' -', p, 'FOUND' if os.path.exists(p) else 'missing')\n",
    "    print('\\nLabel file:', LABELS_CSV, 'FOUND' if os.path.exists(LABELS_CSV) else 'missing')\n",
    "    print('\\nArtifacts dir (after failure) contents:')\n",
    "    if os.path.exists(OUTPUT_ARTIFACTS_DIR):\n",
    "        for fp in glob.glob(os.path.join(OUTPUT_ARTIFACTS_DIR,'*')):\n",
    "            print(' -', os.path.basename(fp))\n",
    "    else:\n",
    "        print(' (artifacts dir not created)')\n",
    "    import inspect as _insp\n",
    "    from sklearn.calibration import CalibratedClassifierCV as _CC\n",
    "    print('CalibratedClassifierCV signature:', _insp.signature(_CC))\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9df2c664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifacts root contents:\n",
      "20250905_141147/\n",
      "  labels.csv\n",
      "  data/\n",
      "    cohort_snapshot.csv\n",
      "    labels.csv\n",
      "  models/\n",
      "    feature_columns.json\n",
      "    metrics.json\n",
      "    model_mortality.joblib\n",
      "    model_prolonged_los.joblib\n",
      "    model_readmission.joblib\n",
      "    mortality_calibration.png\n",
      "    mortality_curves.json\n",
      "    mortality_pr.png\n",
      "    mortality_roc.png\n",
      "    preprocessor.joblib\n",
      "    prolonged_los_calibration.png\n",
      "    prolonged_los_curves.json\n",
      "    prolonged_los_pr.png\n",
      "    prolonged_los_roc.png\n",
      "    readmission_calibration.png\n",
      "    readmission_curves.json\n",
      "    readmission_pr.png\n",
      "    readmission_roc.png\n",
      "    run_metadata.json\n",
      "\n",
      "metrics.json:\n",
      "{\n",
      "  \"mortality\": {\n",
      "    \"n\": 5695,\n",
      "    \"positives\": 622,\n",
      "    \"prevalence\": 0.10921861281826163,\n",
      "    \"roc_auc\": 0.8229600247955413,\n",
      "    \"pr_auc\": 0.37501952036150565,\n",
      "    \"brier\": 0.08109804094620389,\n",
      "    \"ece\": 0.007166416276734353,\n",
      "    \"threshold\": 0.2051432121558919,\n",
      "    \"precision\": 0.34965719882468166,\n",
      "    \"recall\": 0.5739549839228296,\n",
      "    \"f1\": 0.4345709068776628,\n",
      "    \"specificity\": 0.8691109796964321,\n",
      "    \"accuracy\": 0.8368744512730465,\n",
      "    \"cm\": {\n",
      "      \"tp\": 357,\n",
      "      \"tn\": 4409,\n",
      "      \"fp\": 664,\n",
      "      \"fn\": 265\n",
      "    },\n",
      "    \"calibration_bins\": {\n",
      "      \"bin\": [\n",
      "        \"(0.00562, 0.0118]\",\n",
      "        \"(0.0118, 0.0141]\",\n",
      "        \"(0.0141, 0.0197]\",\n",
      "        \"(0.0197, 0.0399]\",\n",
      "        \"(0.0399, 0.0585]\",\n",
      "        \"(0.0585, 0.087]\",\n",
      "        \"(0.087, 0.127]\",\n",
      "        \"(0.127, 0.189]\",\n",
      "        \"(0.189, 0.303]\",\n",
      "        \"(0.303, 0.686]\"\n",
      "      ],\n",
      "      \"count\": [\n",
      "        610,\n",
      "        535,\n",
      "        582,\n",
      "        553,\n",
      "        569,\n",
      "        568,\n",
      "        569,\n",
      "        570,\n",
      "        569,\n",
      "        570\n",
      "      ],\n",
      "      \"mean_proba\": [\n",
      "        0.01027951262794026,\n",
      "        0.012566900349385127,\n",
      "        0.016633799617164637,\n",
      "        0.029848427359329313,\n",
      "        0.04900049882338866,\n",
      "        0.07190209956126008,\n",
      "        0.10564927009605228,\n",
      "        0.1590452350231806,\n",
      "        0.23781582365005535,\n",
      "        0.41992147078859204\n",
      "      ],\n",
      "      \"empirical_rate\": [\n",
      "        0.013114754098360656,\n",
      "        0.007476635514018692,\n",
      "        0.00859106529209622,\n",
      "        0.02531645569620253,\n",
      "        0.056239015817223195,\n",
      "        0.06866197183098592,\n",
      "        0.12126537785588752,\n",
      "        0.14912280701754385,\n",
      "        0.22495606326889278,\n",
      "        0.41754385964912283\n",
      "      ]\n",
      "    }\n",
      "  },\n",
      "  \"prolonged_los\": {\n",
      "    \"n\": 5695,\n",
      "    \"positives\": 2976,\n",
      "    \"prevalence\": 0.5225636523266023,\n",
      "    \"roc_auc\": 0.800064423689133,\n",
      "    \"pr_auc\": 0.7942430868980952,\n",
      "    \"brier\": 0.18180214325606792,\n",
      "    \"ece\": 0.013212147113302918,\n",
      "    \"threshold\": 0.3817810699240758,\n",
      "    \"precision\": 0.6844229217110573,\n",
      "    \"recall\": 0.8548387096774194,\n",
      "    \"f1\": 0.7601972209771403,\n",
      "    \"specificity\": 0.5685913938948143,\n",
      "    \"accuracy\": 0.7181738366988587,\n",
      "    \"cm\": {\n",
      "      \"tp\": 2544,\n",
      "      \"tn\": 1546,\n",
      "      \"fp\": 1173,\n",
      "      \"fn\": 432\n",
      "    },\n",
      "    \"calibration_bins\": {\n",
      "      \"bin\": [\n",
      "        \"(0.0287, 0.181]\",\n",
      "        \"(0.181, 0.275]\",\n",
      "        \"(0.275, 0.336]\",\n",
      "        \"(0.336, 0.436]\",\n",
      "        \"(0.436, 0.521]\",\n",
      "        \"(0.521, 0.619]\",\n",
      "        \"(0.619, 0.722]\",\n",
      "        \"(0.722, 0.824]\",\n",
      "        \"(0.824, 0.852]\",\n",
      "        \"(0.852, 0.918]\"\n",
      "      ],\n",
      "      \"count\": [\n",
      "        570,\n",
      "        579,\n",
      "        569,\n",
      "        560,\n",
      "        570,\n",
      "        569,\n",
      "        569,\n",
      "        610,\n",
      "        683,\n",
      "        416\n",
      "      ],\n",
      "      \"mean_proba\": [\n",
      "        0.12353508726102315,\n",
      "        0.2310733385433003,\n",
      "        0.3100600122217649,\n",
      "        0.38615402395553383,\n",
      "        0.4845198489105784,\n",
      "        0.5639232461919769,\n",
      "        0.6684976654834519,\n",
      "        0.7800433601306165,\n",
      "        0.8439750340224361,\n",
      "        0.8550315599555245\n",
      "      ],\n",
      "      \"empirical_rate\": [\n",
      "        0.09824561403508772,\n",
      "        0.22797927461139897,\n",
      "        0.27240773286467485,\n",
      "        0.3821428571428571,\n",
      "        0.49473684210526314,\n",
      "        0.562390158172232,\n",
      "        0.6836555360281195,\n",
      "        0.7918032786885246,\n",
      "        0.849194729136164,\n",
      "        0.8774038461538461\n",
      "      ]\n",
      "    }\n",
      "  },\n",
      "  \"readmission\": {\n",
      "    \"n\": 5695,\n",
      "    \"positives\": 246,\n",
      "    \"prevalence\": 0.04319578577699736,\n",
      "    \"roc_auc\": 0.5954187909469479,\n",
      "    \"pr_auc\": 0.06010391502213744,\n",
      "    \"brier\": 0.04115138553311081,\n",
      "    \"ece\": 0.005452363120499873,\n",
      "    \"threshold\": 0.06211457976685655,\n",
      "    \"precision\": 0.08380681818181818,\n",
      "    \"recall\": 0.23983739837398374,\n",
      "    \"f1\": 0.12421052631578948,\n",
      "    \"specificity\": 0.8816296568177647,\n",
      "    \"accuracy\": 0.8539069359086918,\n",
      "    \"cm\": {\n",
      "      \"tp\": 59,\n",
      "      \"tn\": 4804,\n",
      "      \"fp\": 645,\n",
      "      \"fn\": 187\n",
      "    },\n",
      "    \"calibration_bins\": {\n",
      "      \"bin\": [\n",
      "        \"(-0.001, 0.0207]\",\n",
      "        \"(0.0207, 0.0271]\",\n",
      "        \"(0.0271, 0.0338]\",\n",
      "        \"(0.0338, 0.0407]\",\n",
      "        \"(0.0407, 0.0448]\",\n",
      "        \"(0.0448, 0.0481]\",\n",
      "        \"(0.0481, 0.0517]\",\n",
      "        \"(0.0517, 0.0562]\",\n",
      "        \"(0.0562, 0.0631]\",\n",
      "        \"(0.0631, 0.0998]\"\n",
      "      ],\n",
      "      \"count\": [\n",
      "        638,\n",
      "        501,\n",
      "        570,\n",
      "        570,\n",
      "        571,\n",
      "        580,\n",
      "        556,\n",
      "        571,\n",
      "        611,\n",
      "        527\n",
      "      ],\n",
      "      \"mean_proba\": [\n",
      "        0.01856007688886394,\n",
      "        0.024069405685576133,\n",
      "        0.030150848032505857,\n",
      "        0.037320306099604815,\n",
      "        0.042764371040249924,\n",
      "        0.04656973628770959,\n",
      "        0.04977866080651539,\n",
      "        0.05338740746657294,\n",
      "        0.059835591059438156,\n",
      "        0.07350991838688423\n",
      "      ],\n",
      "      \"empirical_rate\": [\n",
      "        0.02037617554858934,\n",
      "        0.027944111776447105,\n",
      "        0.042105263157894736,\n",
      "        0.04035087719298246,\n",
      "        0.03502626970227671,\n",
      "        0.034482758620689655,\n",
      "        0.048561151079136694,\n",
      "        0.050788091068301226,\n",
      "        0.05564648117839607,\n",
      "        0.07969639468690702\n",
      "      ]\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Inspect saved artifacts\n",
    "import json, glob\n",
    "print('Artifacts root contents:')\n",
    "for root, dirs, files in os.walk(ARTIFACTS_DIR):\n",
    "    level = root.replace(ARTIFACTS_DIR, '').count(os.sep)\n",
    "    indent = '  ' * level\n",
    "    print(f\"{indent}{os.path.basename(root) or ARTIFACTS_DIR}/\")\n",
    "    subindent = '  ' * (level + 1)\n",
    "    for f in files:\n",
    "        print(f\"{subindent}{f}\")\n",
    "metrics_path = os.path.join(OUTPUT_MODELS_DIR, 'metrics.json')\n",
    "if os.path.exists(metrics_path):\n",
    "    print('\\nmetrics.json:')\n",
    "    print(open(metrics_path,'r',encoding='utf-8').read())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
